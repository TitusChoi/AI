{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Jupyter]NeuralNetwork(TF).ipynb\n",
    "Description   : neural network using tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 초기화(Initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.9019016  0.19189548 0.83535385 0.2148422 ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rand = tf.random.uniform([4], 0 , 1) # Uniform Distribution\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.254974   0.80561745 0.5313208  0.47745478 0.508258   0.5443969 ]\n",
      "  [0.07627499 0.25238526 0.6709105  0.62702024 0.8268635  0.5993198 ]\n",
      "  [0.08183289 0.22258234 0.0807966  0.55063176 0.09597015 0.09971571]\n",
      "  [0.11381924 0.38233864 0.31818056 0.3142823  0.21558487 0.6450577 ]\n",
      "  [0.6002799  0.24669755 0.41557038 0.22740054 0.7357801  0.94598246]]\n",
      "\n",
      " [[0.12587678 0.89267457 0.28067684 0.4187584  0.24995828 0.21514452]\n",
      "  [0.61380744 0.42460203 0.62127733 0.18233716 0.5241616  0.8847313 ]\n",
      "  [0.07067132 0.23741353 0.10048449 0.05304801 0.8267113  0.16116977]\n",
      "  [0.25787103 0.6599523  0.39466238 0.93473005 0.59148705 0.3185959 ]\n",
      "  [0.18292952 0.3709954  0.5861709  0.45449364 0.1622026  0.23639095]]\n",
      "\n",
      " [[0.33914208 0.177405   0.08192599 0.5946685  0.2222259  0.75217366]\n",
      "  [0.44368553 0.32891238 0.33198857 0.9556061  0.04474556 0.55050075]\n",
      "  [0.91526854 0.85343957 0.8011565  0.0154587  0.19095695 0.81667006]\n",
      "  [0.10337627 0.5380144  0.54897964 0.15982676 0.86594176 0.9705452 ]\n",
      "  [0.5451683  0.6833346  0.48431444 0.6301043  0.1354729  0.23045862]]\n",
      "\n",
      " [[0.80578375 0.8198092  0.59032893 0.8588402  0.3897885  0.60846543]\n",
      "  [0.4970044  0.4882697  0.16425598 0.99332523 0.3980347  0.19182003]\n",
      "  [0.4011525  0.99894357 0.74563706 0.6552036  0.33449018 0.0157423 ]\n",
      "  [0.7613107  0.94225943 0.22897005 0.02935553 0.31703103 0.95539176]\n",
      "  [0.99820817 0.37700403 0.0562731  0.5450951  0.85578895 0.62153435]]\n",
      "\n",
      " [[0.1154083  0.5841396  0.8382076  0.5675478  0.93119216 0.18059838]\n",
      "  [0.00397408 0.01198006 0.13765526 0.9400041  0.5785495  0.2279433 ]\n",
      "  [0.31118727 0.5759599  0.88952863 0.2092222  0.4529047  0.2804849 ]\n",
      "  [0.3078593  0.02977014 0.26373577 0.95048976 0.7061695  0.05641592]\n",
      "  [0.9529034  0.9482837  0.13173485 0.7361381  0.3164047  0.8301188 ]]], shape=(5, 5, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rand = tf.random.uniform([5, 5, 6], 0 , 1) # Uniform Distribution\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-1.9699517  -0.03726453  0.52845234 -0.94855183  0.42665833], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rand = tf.random.normal([5], 0 , 1) # Normal Distribution(list, mean, standard deviation)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 활성화 함수(Activation Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활성화 함수 역할을 해주는 sigmoid 활성화 함수의 정의는 다음과 같다.\n",
    "$$f(x) = {\\frac{1}{1 + e^{-x}}}$$\n",
    "이를 통해 예측 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6903390540880461\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "x = 1 # 입력값\n",
    "y = 0 # 기대값\n",
    "w = tf.random.normal([1], 0, 1) # initial weight\n",
    "y_p = sigmoid(x * w)            # y predict : 신경망 연산을 수행\n",
    "print(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 : 0, 에러값 : -0.7649345263356699, 결과값 : 0.7649345263356699\n",
      "반복 횟수 : 100, 에러값 : -0.12135700249214545, 결과값 : 0.12135700249214545\n",
      "반복 횟수 : 200, 에러값 : -0.05728466410801294, 결과값 : 0.05728466410801294\n",
      "반복 횟수 : 300, 에러값 : -0.037009048852389335, 결과값 : 0.037009048852389335\n",
      "반복 횟수 : 400, 에러값 : -0.027233879259464955, 결과값 : 0.027233879259464955\n",
      "반복 횟수 : 500, 에러값 : -0.021510469605694176, 결과값 : 0.021510469605694176\n",
      "반복 횟수 : 600, 에러값 : -0.01776098051437138, 결과값 : 0.01776098051437138\n",
      "반복 횟수 : 700, 에러값 : -0.015117737427000783, 결과값 : 0.015117737427000783\n",
      "반복 횟수 : 800, 에러값 : -0.01315558442492496, 결과값 : 0.01315558442492496\n",
      "반복 횟수 : 900, 에러값 : -0.011642026641020856, 결과값 : 0.011642026641020856\n"
     ]
    }
   ],
   "source": [
    "a = 0.1 # a는 학습률\n",
    "for index in range(1000): # 1000번의 학습\n",
    "    y_p = sigmoid(x * w)\n",
    "    error = y - y_p\n",
    "    \n",
    "    # 학습 또는 갱신\n",
    "    w = w + x * a * error\n",
    "    if index % 100 == 0:\n",
    "        print('반복 횟수 : {0}, 에러값 : {1}, 결과값 : {2}'.format(index, error, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 : 0, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 100, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 200, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 300, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 400, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 500, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 600, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 700, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 800, 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 : 900, 에러값 : 0.5, 결과값 : 0.5\n"
     ]
    }
   ],
   "source": [
    "# 조건 변경, 입력값과 출력값 변경\n",
    "\n",
    "x = 0 # 입력값 1 -> 0\n",
    "y = 1 # 기대값 0 -> 1\n",
    "w = tf.random.normal([1], 0, 1) # 초기 가중치\n",
    "a = 0.1 # a는 학습률\n",
    "for index in range(1000):\n",
    "    y_p = sigmoid(x * w)\n",
    "    error = y - y_p\n",
    "    \n",
    "    # 학습 또는 갱신\n",
    "    w = w + x * a * error\n",
    "    if index % 100 == 0:\n",
    "        print('반복 횟수 : {0}, 에러값 : {1}, 결과값 : {2}'.format(index, error, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식은 왜 에러값에 예측을 수행하지 못했을까?<br>\n",
    "입력 값이 0이고, 0이 곱해졌기 때문에 학습을 제대로 수행하지 못한 것이다.<br>\n",
    "그렇기 때문에 이를 방지하기 위한 아이디어가 필요하다.<br>\n",
    "이때 등장하는 개념이 바로 편향($b$)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 : 0, 에러값 : 0.8110605278927676, 결과값 : 0.18893947210723236\n",
      "반복 횟수 : 100, 에러값 : 0.12605333649056238, 결과값 : 0.8739466635094376\n",
      "반복 횟수 : 200, 에러값 : 0.05838560908478185, 결과값 : 0.9416143909152181\n",
      "반복 횟수 : 300, 에러값 : 0.037475168696035066, 결과값 : 0.9625248313039649\n",
      "반복 횟수 : 400, 에러값 : 0.027487944912289786, 결과값 : 0.9725120550877102\n",
      "반복 횟수 : 500, 에러값 : 0.021669541219105137, 결과값 : 0.9783304587808949\n",
      "반복 횟수 : 600, 에러값 : 0.01786968152068724, 결과값 : 0.9821303184793128\n",
      "반복 횟수 : 700, 에러값 : 0.01519662558806234, 결과값 : 0.9848033744119377\n",
      "반복 횟수 : 800, 에러값 : 0.013215395028018717, 결과값 : 0.9867846049719813\n",
      "반복 횟수 : 900, 에러값 : 0.0116889324813918, 결과값 : 0.9883110675186082\n"
     ]
    }
   ],
   "source": [
    "# 조건 변경, 입력값과 출력값 변경, 편향 적용\n",
    "\n",
    "x = 0 # 입력값 1 -> 0\n",
    "y = 1 # 기대값 0 -> 1\n",
    "w = tf.random.normal([1], 0, 1) # 초기 가중치\n",
    "b = tf.random.normal([1], 0, 1) # 초기 편향\n",
    "a = 0.1 # a는 학습률\n",
    "b_x = 1 # bias에 넣어주기 위한 input\n",
    "\n",
    "epochs = 1000 # epoch 정의 : 학습횟수\n",
    "for index in range(epochs):\n",
    "    y_p = sigmoid(x * w + b_x * b)\n",
    "    error = y - y_p\n",
    "    \n",
    "    # 학습 또는 갱신\n",
    "    w = w + x * a * error\n",
    "    b = b + b_x * a * error\n",
    "\n",
    "    # 전부 출력하는 것이 아니라 100번 반복마다 출력해보자.\n",
    "    if index % 100 == 0:\n",
    "        print('반복 횟수 : {0}, 에러값 : {1}, 결과값 : {2}'.format(index, error, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 경우를 방지하기 위해 편향을 넣는다.<br>\n",
    "편향($b$)의 입력으로는 보편적으로 1을 곱해서 넣는다.<br>\n",
    "편향은 $w$처럼 난수 형태로 넣어준다.<br>\n",
    "따라서 예측값($y_p$)의 최종 식은 다음과 같다.\n",
    "$$y_p = f(x \\times w + 1 \\times b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크(Network) : XOR, OR, AND 구현하고 XOR 특히 신경쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 : 0, 에러값 : -0.7574656489177307, 누적에러값 : -1.4777394093995833\n",
      "반복 횟수 : 200, 에러값 : -0.006863813523641005, 누적에러값 : -0.20973469050570315\n",
      "반복 횟수 : 400, 에러값 : -0.00011036990014900048, 누적에러값 : -0.205974760378278\n",
      "반복 횟수 : 600, 에러값 : -1.7956329638401456e-06, 누적에러값 : -0.2059123440256146\n",
      "반복 횟수 : 800, 에러값 : -2.9219355798504143e-08, 누적에러값 : -0.20591702284088492\n",
      "반복 횟수 : 1000, 에러값 : -4.754394333632275e-10, 누적에러값 : -0.20591742736080237\n",
      "반복 횟수 : 1200, 에러값 : -7.736058589515124e-12, 누적에러값 : -0.20591742642539562\n",
      "반복 횟수 : 1400, 에러값 : -1.258763961784254e-13, 누적에러값 : -0.20591742641017524\n",
      "반복 횟수 : 1600, 에러값 : -2.0481834426931876e-15, 누적에러값 : -0.20591833881270438\n",
      "반복 횟수 : 1800, 에러값 : -3.332678359313419e-17, 누적에러값 : -0.20591741479735542\n",
      "X :  [1 1] , Y :  [1] , Output :  0.5881750528487434\n",
      "X :  [1 0] , Y :  [0] , Output :  4.904539113954092e-36\n",
      "X :  [0 1] , Y :  [0] , Output :  1.0\n",
      "X :  [0 0] , Y :  [0] , Output :  5.53555065201985e-19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# AND 연산자 신경망 구현\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [0], [0], [0]])\n",
    "\n",
    "# 파라미터 초기화 과정, mean 0, std dev 1\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1 # bias에 넣어주기 위한 input\n",
    "\n",
    "epochs = 2000 # 학습횟수\n",
    "a = 0.1 # 학습률\n",
    "length_datasets = len(y)\n",
    "\n",
    "for i in range(epochs):\n",
    "    error_sum = 0\n",
    "    for j in range(length_datasets):\n",
    "        y_p = sigmoid(np.sum(x[j][0] * w) + b_x * b)\n",
    "        error = y[j][0] - y_p\n",
    "        \n",
    "        # 학습 또는 갱신\n",
    "        w = w + x[j] * a * error\n",
    "        b = b + b_x * a * error\n",
    "        error_sum += error # 누적 에러\n",
    "        \n",
    "        # 전부 출력하는 것이 아니라 100번 반복마다 출력해보자.\n",
    "    if i % 200 == 0:\n",
    "        print('반복 횟수 : {0}, 에러값 : {1}, 누적에러값 : {2}'.format(i, error, error_sum))\n",
    "        \n",
    "for i in range(length_datasets):\n",
    "    print(\"X : \", x[i], \", Y : \", y[i], \", Output : \", sigmoid(np.sum(x[i] * w) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 다중 퍼셉트론 : keras 통해서  XOR 구현해서 비교해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
