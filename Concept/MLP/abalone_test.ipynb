{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abalone_test.ipynb\n",
    "Description   : Multiple layer perceptron to solve general problems<br>\n",
    "기존에 전복 데이터를 시험하기 위한 파일이다. 기능은 abalone.ipynb에 구현되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run abalone.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Train - loss = 12.158, accuracy = 0.785 / Test = 0.792\n",
      "Epoch 20 : Train - loss = 7.852, accuracy = 0.820 / Test = 0.813\n",
      "Epoch 30 : Train - loss = 7.611, accuracy = 0.812 / Test = 0.807\n",
      "Epoch 40 : Train - loss = 7.530, accuracy = 0.810 / Test = 0.806\n",
      "Epoch 50 : Train - loss = 7.465, accuracy = 0.809 / Test = 0.806\n",
      "Epoch 60 : Train - loss = 7.410, accuracy = 0.809 / Test = 0.806\n",
      "Epoch 70 : Train - loss = 7.361, accuracy = 0.809 / Test = 0.806\n",
      "Epoch 80 : Train - loss = 7.318, accuracy = 0.809 / Test = 0.807\n",
      "Epoch 90 : Train - loss = 7.279, accuracy = 0.809 / Test = 0.807\n",
      "Epoch 100 : Train - loss = 7.244, accuracy = 0.809 / Test = 0.807\n",
      "Epoch 110 : Train - loss = 7.212, accuracy = 0.809 / Test = 0.807\n",
      "Epoch 120 : Train - loss = 7.183, accuracy = 0.809 / Test = 0.807\n",
      "Epoch 130 : Train - loss = 7.156, accuracy = 0.809 / Test = 0.808\n",
      "Epoch 140 : Train - loss = 7.131, accuracy = 0.809 / Test = 0.808\n",
      "Epoch 150 : Train - loss = 7.108, accuracy = 0.809 / Test = 0.808\n",
      "Epoch 160 : Train - loss = 7.087, accuracy = 0.809 / Test = 0.808\n",
      "Epoch 170 : Train - loss = 7.067, accuracy = 0.809 / Test = 0.808\n",
      "Epoch 180 : Train - loss = 7.049, accuracy = 0.809 / Test = 0.809\n",
      "Epoch 190 : Train - loss = 7.031, accuracy = 0.809 / Test = 0.809\n",
      "Epoch 200 : Train - loss = 7.015, accuracy = 0.809 / Test = 0.809\n",
      "Epoch 210 : Train - loss = 7.000, accuracy = 0.809 / Test = 0.809\n",
      "Epoch 220 : Train - loss = 6.985, accuracy = 0.810 / Test = 0.809\n",
      "Epoch 230 : Train - loss = 6.971, accuracy = 0.810 / Test = 0.809\n",
      "Epoch 240 : Train - loss = 6.958, accuracy = 0.810 / Test = 0.809\n",
      "Epoch 250 : Train - loss = 6.946, accuracy = 0.810 / Test = 0.809\n",
      "Epoch 260 : Train - loss = 6.934, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 270 : Train - loss = 6.922, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 280 : Train - loss = 6.911, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 290 : Train - loss = 6.901, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 300 : Train - loss = 6.890, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 310 : Train - loss = 6.880, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 320 : Train - loss = 6.870, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 330 : Train - loss = 6.861, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 340 : Train - loss = 6.852, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 350 : Train - loss = 6.842, accuracy = 0.810 / Test = 0.810\n",
      "Epoch 360 : Train - loss = 6.834, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 370 : Train - loss = 6.825, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 380 : Train - loss = 6.817, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 390 : Train - loss = 6.808, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 400 : Train - loss = 6.800, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 410 : Train - loss = 6.792, accuracy = 0.810 / Test = 0.811\n",
      "Epoch 420 : Train - loss = 6.784, accuracy = 0.811 / Test = 0.811\n",
      "Epoch 430 : Train - loss = 6.776, accuracy = 0.811 / Test = 0.811\n",
      "Epoch 440 : Train - loss = 6.768, accuracy = 0.811 / Test = 0.811\n",
      "Epoch 450 : Train - loss = 6.761, accuracy = 0.811 / Test = 0.811\n",
      "Epoch 460 : Train - loss = 6.753, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 470 : Train - loss = 6.745, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 480 : Train - loss = 6.738, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 490 : Train - loss = 6.731, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 500 : Train - loss = 6.723, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 510 : Train - loss = 6.716, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 520 : Train - loss = 6.709, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 530 : Train - loss = 6.702, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 540 : Train - loss = 6.694, accuracy = 0.811 / Test = 0.812\n",
      "Epoch 550 : Train - loss = 6.687, accuracy = 0.812 / Test = 0.812\n",
      "Epoch 560 : Train - loss = 6.680, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 570 : Train - loss = 6.673, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 580 : Train - loss = 6.666, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 590 : Train - loss = 6.659, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 600 : Train - loss = 6.652, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 610 : Train - loss = 6.646, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 620 : Train - loss = 6.639, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 630 : Train - loss = 6.632, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 640 : Train - loss = 6.625, accuracy = 0.812 / Test = 0.813\n",
      "Epoch 650 : Train - loss = 6.619, accuracy = 0.812 / Test = 0.814\n",
      "Epoch 660 : Train - loss = 6.612, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 670 : Train - loss = 6.605, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 680 : Train - loss = 6.599, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 690 : Train - loss = 6.592, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 700 : Train - loss = 6.586, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 710 : Train - loss = 6.579, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 720 : Train - loss = 6.573, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 730 : Train - loss = 6.567, accuracy = 0.813 / Test = 0.814\n",
      "Epoch 740 : Train - loss = 6.560, accuracy = 0.813 / Test = 0.815\n",
      "Epoch 750 : Train - loss = 6.554, accuracy = 0.813 / Test = 0.815\n",
      "Epoch 760 : Train - loss = 6.547, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 770 : Train - loss = 6.541, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 780 : Train - loss = 6.535, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 790 : Train - loss = 6.528, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 800 : Train - loss = 6.522, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 810 : Train - loss = 6.516, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 820 : Train - loss = 6.510, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 830 : Train - loss = 6.503, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 840 : Train - loss = 6.497, accuracy = 0.814 / Test = 0.815\n",
      "Epoch 850 : Train - loss = 6.491, accuracy = 0.814 / Test = 0.816\n",
      "Epoch 860 : Train - loss = 6.485, accuracy = 0.814 / Test = 0.816\n",
      "Epoch 870 : Train - loss = 6.479, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 880 : Train - loss = 6.473, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 890 : Train - loss = 6.467, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 900 : Train - loss = 6.461, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 910 : Train - loss = 6.455, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 920 : Train - loss = 6.449, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 930 : Train - loss = 6.443, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 940 : Train - loss = 6.437, accuracy = 0.815 / Test = 0.816\n",
      "Epoch 950 : Train - loss = 6.431, accuracy = 0.815 / Test = 0.817\n",
      "Epoch 960 : Train - loss = 6.426, accuracy = 0.815 / Test = 0.817\n",
      "Epoch 970 : Train - loss = 6.420, accuracy = 0.815 / Test = 0.817\n",
      "Epoch 980 : Train - loss = 6.414, accuracy = 0.816 / Test = 0.817\n",
      "Epoch 990 : Train - loss = 6.408, accuracy = 0.816 / Test = 0.817\n",
      "Epoch 1000 : Train - loss = 6.403, accuracy = 0.816 / Test = 0.817\n",
      "\n",
      " 최종 테스트 : Final accuracy = 0.817\n"
     ]
    }
   ],
   "source": [
    "regression_exec(epoch_count=1000, mb_size=100, report=10, train_rate=0.7)                                              #메인함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1616650025194,
     "user": {
      "displayName": "J.H Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXbQ4H4DovEvK-CyOR647ftdReBCjlMLx98Z5_qw=s64",
      "userId": "17750727185697517622"
     },
     "user_tz": -540
    },
    "id": "Rrub9bKiKpMY",
    "outputId": "4c3afae9-377b-4960-f179-389dd97e0f0e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63183398]\n",
      " [ 1.84088443]\n",
      " [ 1.96896077]\n",
      " [ 2.59983994]\n",
      " [ 2.36603883]\n",
      " [ 1.25409388]\n",
      " [ 2.1541923 ]\n",
      " [-2.76890992]\n",
      " [-0.00603575]\n",
      " [ 3.10927615]]\n",
      "[4.43018536]\n"
     ]
    }
   ],
   "source": [
    "#갱신이 완료된 가중치와 편향 값을 확인하여 봅시다.\n",
    "print(weight)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CGFO33J9KpMZ",
    "outputId": "0bdee20b-16cb-4ad4-e834-c802d202cd05",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Train - loss = 7.028, accuracy = 0.839 / Test = 0.815\n",
      "\n",
      " 최종 테스트 : Final accuracy = 0.815\n"
     ]
    }
   ],
   "source": [
    "#하이퍼파라미터를 수정하여 새로운 실험을 수행하여 봅시다.\n",
    "LEARNING_RATE = 0.01\n",
    "regression_exec(epoch_count =  10, mb_size =  10, report =  10, train_rate =  0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1616650364936,
     "user": {
      "displayName": "J.H Lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXbQ4H4DovEvK-CyOR647ftdReBCjlMLx98Z5_qw=s64",
      "userId": "17750727185697517622"
     },
     "user_tz": -540
    },
    "id": "PVt3pJiEKpMa",
    "outputId": "c3290564-19ce-476d-bcfb-abef4848e601",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.76546195]\n"
     ]
    }
   ],
   "source": [
    "#새로운 데이터를 할당하여 이 데이터를 가진 전복의 나이를 예측하여 보겠습니다.\n",
    "new_x = [0, 1, 0, 0.685,0.545, 0.18,1.42,0.674,0.392,0.5]\n",
    "output = forward_neuralnet(new_x)\n",
    "\n",
    "print(output[0] + 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-vRKZ1s3uUa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "신경망(회귀)_사전배포.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
