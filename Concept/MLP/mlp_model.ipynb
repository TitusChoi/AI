{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlp_model.ipynb\n",
    "Description   : Multiple layer perceptron to solve general problems<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'.../mathutil.ipynb.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\tituschoi\\desktop\\library\\codelion\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tituschoi\\desktop\\library\\codelion\\lib\\site-packages\\IPython\\utils\\path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[1;34m(name, force_win32)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File `%r` not found.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File `'.../mathutil.ipynb.py'` not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-edd37c28b446>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# mathutil library 불러오기, activation function 영역\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.../mathutil.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tituschoi\\desktop\\library\\codelion\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2342\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2343\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2344\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2345\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tituschoi\\desktop\\library\\codelion\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tituschoi\\desktop\\library\\codelion\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"^'.*'$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: File `'.../mathutil.ipynb.py'` not found."
     ]
    }
   ],
   "source": [
    "# mathutil library 불러오기, activation function 영역\n",
    "%run .../mathutil.ipynb\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class\n",
    "class Model(object):\n",
    "    def __init__(self, name, dataset):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        # 다른 설정값이 더 있을 때\n",
    "        if not hasattr(self, 'rand_std') : self.rand_std = 0.030\n",
    "    \n",
    "    # 문자열을 초기화\n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "    \n",
    "    # main function, 훈련값, 미니배치 사이즈, 훈련율, 훈련 중간 기록 횟수, 시각화 몇번 해줄 것인지?, \n",
    "    def exec_all(self, epochs = 10, mb_size = 10, lr = 0.001, report = 1, show = 1):\n",
    "        self.train(epochs, mb, lr, report)\n",
    "        self.test()\n",
    "        if show > 0:\n",
    "            self.visualize(show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpModel(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        # class 상속을 통해 model에서 사용하는 정보를 가져옴\n",
    "        super(MlpModel, self).__init__(name, dataset)\n",
    "        self.init_parameters(hconfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter initialization\n",
    "def mlp_init_parameters(self, hconfigs):\n",
    "    self.hconfigs = hconfigs\n",
    "    self.pm_hiddens = []\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    \n",
    "    for hconfig in hconfigs:\n",
    "        pm_hidden, prev_shape = self.alloc_layer_param(prev_shape, hconfig)\n",
    "        self.pm_hiddens.append(pm_hidden)\n",
    "        \n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    self.pm_output, _ = self.alloc_layer_param(prev_shape, output_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter layer initialization\n",
    "def mlp_alloc_layer_param(self, input_shape, hconfig):\n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = hconfig\n",
    "\n",
    "    weight, bias = self.alloc_param_pair([input_cnt, output_cnt])\n",
    "\n",
    "    return {'w':weight, 'b':bias}, output_cnt\n",
    "\n",
    "MlpModel.alloc_layer_param = mlp_alloc_layer_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight, bias initialization\n",
    "def mlp_alloc_param_pair(self, shape):\n",
    "    weight = np.random.normal(0, self.rand_std, shape)\n",
    "    bias = np.zeros([shape[-1]])\n",
    "    return weight, bias\n",
    "\n",
    "MlpModel.init_parameters = mlp_init_parameters\n",
    "MlpModel.alloc_layer_param = mlp_alloc_layer_param\n",
    "MlpModel.alloc_param_pair = mlp_alloc_param_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_train(self, epochs = 10, mb_size = 10, lr = 0.001, report = 0):\n",
    "    self.lr = lr\n",
    "    \n",
    "    batch_cnt = int(self.dataset.train_count / mb_size)\n",
    "    time1 = time2 = int(time.time())\n",
    "    if report != 0:\n",
    "        print('Model {} train started:'.format(self.name))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        self.dataset.shuffle_train_data(mb_size * batch_cnt)\n",
    "        for n in range(batch_cnt):\n",
    "            trX, trY = self.dataset.get_train_data(mb_size, n)\n",
    "            cost, acc = self.train_step(trX, trY)\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "\n",
    "        if report > 0 and (epoch + 1) % report == 0:\n",
    "            vaX, vaY = self.dataset.get_validate_data(100)\n",
    "            acc = self.eval_accuracy(vaX, vaY)\n",
    "            time3 = int(time.time())\n",
    "            tm1, tm2 = time3 - time2, time3 - time1 # time per epoch, total time \n",
    "            self.dataset.train_prt_result(epoch + 1, costs, accs, acc, tm1, tm2)\n",
    "            time2 = time3\n",
    "\n",
    "    tm_total = int(time.time()) - time1\n",
    "    print('Model {} train ended in {} secs:'.format(self.name, tm_total))\n",
    "    \n",
    "MlpModel.train = mlp_model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_test(self):\n",
    "    teX, teY = self.dataset.get_test_data()\n",
    "    time1 = int(time.time())\n",
    "    acc = self.eval_accuracy(teX, teY)\n",
    "    time2 = int(time.time())\n",
    "    self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "MlpModel.test = mlp_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_visualize(self, num):\n",
    "    print('Model {} Visualization'.format(self.name))\n",
    "    deX, deY = self.dataset.get_visualize_data(num)\n",
    "    est = self.get_estimate(deX)\n",
    "    self.dataset.visualize(deX, est, deY)\n",
    "\n",
    "MlpModel.visualize = mlp_model_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train_step(self, x, y):\n",
    "    \n",
    "    output, aux_nn = self.forward_neuralnet(x)\n",
    "    loss, aux_pp = self.forward_postproc(output, y)\n",
    "    accuracy = self.eval_accuracy(x, y, output)\n",
    "    \n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "    self.backprop_neuralnet(G_output, aux_nn)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "MlpModel.train_step = mlp_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_neuralnet(self, x):\n",
    "    hidden = x\n",
    "    aux_layers = []\n",
    "\n",
    "    for n, hconfig in enumerate(self.hconfigs):\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_hiddens[n])\n",
    "        aux_layers.append(aux)\n",
    "\n",
    "    output, aux_out = self.forward_layer(hidden, None, self.pm_output)\n",
    "    \n",
    "    return output, [aux_out, aux_layers]\n",
    "\n",
    "MlpModel.forward_neuralnet = mlp_forward_neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_layer(self, x, hconfig, pm):\n",
    "    y = np.matmul(x, pm['w']) + pm['b']\n",
    "    if hconfig is not None: y = relu(y)\n",
    "    return y, [x,y]\n",
    "\n",
    "MlpModel.forward_layer = mlp_forward_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_postproc(self, output, y):\n",
    "    loss, aux_loss = self.dataset.forward_postproc(output, y)\n",
    "    extra, aux_extra = self.forward_extra_cost(y)\n",
    "    return loss + extra, [aux_loss, aux_extra]\n",
    "\n",
    "MlpModel.forward_postproc = mlp_forward_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_extra_cost(self, y):\n",
    "    return 0, None\n",
    "\n",
    "MlpModel.forward_extra_cost = mlp_forward_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy(self, x, y, output=None):\n",
    "    if output is None:\n",
    "        output, _ = self.forward_neuralnet(x)\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n",
    "\n",
    "MlpModel.eval_accuracy = mlp_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_postproc(self, G_loss, aux):\n",
    "    aux_loss, aux_extra = aux\n",
    "    self.backprop_extra_cost(G_loss, aux_extra)\n",
    "    G_output = self.dataset.backprop_postproc(G_loss, aux_loss)\n",
    "    return G_output\n",
    "\n",
    "MlpModel.backprop_postproc = mlp_backprop_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_extra_cost(self, G_loss, aux):\n",
    "    pass\n",
    "\n",
    "MlpModel.backprop_extra_cost = mlp_backprop_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_layer(self, G_y, hconfig, pm, aux):\n",
    "    x, y = aux\n",
    "\n",
    "    if hconfig is not None: G_y = relu_derv(y) * G_y\n",
    "\n",
    "    g_y_weight = x.transpose()\n",
    "    g_y_input = pm['w'].transpose()\n",
    "\n",
    "    G_weight = np.matmul(g_y_weight, G_y)\n",
    "    G_bias = np.sum(G_y, axis=0)\n",
    "    G_input = np.matmul(G_y, g_y_input)\n",
    "\n",
    "    pm['w'] -= self.learning_rate * G_weight\n",
    "    pm['b'] -= self.learning_rate * G_bias\n",
    "\n",
    "    return G_input\n",
    "\n",
    "MlpModel.backprop_layer = mlp_backprop_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_neuralnet(self, G_output, aux):\n",
    "    aux_out, aux_layers = aux\n",
    "    \n",
    "    G_hidden = self.backprop_layer(G_output, None, self.pm_output, aux_out)\n",
    "    \n",
    "    for n in reversed(range(len(self.hconfigs))):\n",
    "        hconfig, pm, aux = self.hconfigs[n], self.pm_hiddens[n], aux_layers[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "        \n",
    "    return G_hidden\n",
    "\n",
    "MlpModel.backprop_neuralnet = mlp_backprop_neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_postproc(self, G_loss, aux):\n",
    "    aux_loss, aux_extra = aux\n",
    "    self.backprop_extra_cost(G_loss, aux_extra)\n",
    "    G_output = self.dataset.backprop_postproc(G_loss, aux_loss)\n",
    "    return G_output\n",
    "\n",
    "MlpModel.backprop_postproc = mlp_backprop_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_extra_cost(self, G_loss, aux):\n",
    "    pass\n",
    "\n",
    "MlpModel.backprop_extra_cost = mlp_backprop_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate(self, x):\n",
    "    output, _ = self.forward_neuralnet(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "MlpModel.get_estimate = mlp_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
